\documentclass{beamer}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usetheme{Madrid}
\title{Tweets Sentiment Analysis}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\author{Kuo-Wei Ho\inst{1}, Hao-Chien Wang\inst{2}}

\institute[NTU]
{
	\inst{1}
	NTUEE
	\and
	\inst{2}
	NTUPhys
}
\date[DSP 2019]
{Data Science Programing,\\July 2019}

\begin{document}

\frame{\titlepage}

\begin{frame}{Table of Contents}
	\tableofcontents[currentsection]
\end{frame}

\begin{frame}{Problem}
	Given a set of data containing 1,600,000 tweets and the sentiment of each tweets. Create a model that can analyze sentiment of new tweets.\\
	{\scriptsize Data: \url{https://www.kaggle.com/kazanova/sentiment140}}
	\begin{table}[htpb]
		\tiny
		\centering
		\caption{Data example}
		\label{tab:data}
		\begin{tabular}{c c c c}
			sentiment & Post ID & User ID & tweets \\
			\hline
			 0 & 1467814192 & Ljelli3166 & blagh class at 8 tomorrow  \\
			 0 & 1467821455 & CiaraRenee & I need a hug  \\
			 4 & 1677796507 & FoodAllergyBuzz & @otibml Thx for the tweet!  \\
			 4 & 1677796519 & Iakido & Sunshine.....I LOVE this weather!!!  \\
		\end{tabular}
	\end{table}
	0: Negative \\
	4: Positive
\end{frame}

\begin{frame}{Tools}
	\begin{itemize}
		\item \textit{GloVe: Global Vectors for Word Representation} by Standford University.
		\item \textit{RNN: Recurrent Neural Netword}
	\end{itemize}
\end{frame}

\begin{frame}{Steps}
	\begin{enumerate}
		\item Clean the data: remove non-UTF8 symbols, numbers and urls.
		\item Combine all tweets into one string and tokenize.
		\item Feed the tokens to GloVe to generate word vectors.
		\item tokenize all tweets and search each words in the vectors to transform it into a list of matrices.
		\item Train RNN with the list of word vectors.
	\end{enumerate}	
\end{frame}
\end{document}


